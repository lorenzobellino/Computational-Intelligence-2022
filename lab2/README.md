# Lab 2 : Set Covering Problem solved by GA
## Task

Given a number $N$ and some lists of integers $P = (L_0, L_1, L_2, ..., L_n)$, 
determine, if possible, $S = (L_{s_0}, L_{s_1}, L_{s_2}, ..., L_{s_n})$
such that each number between $0$ and $N-1$ appears in at least one list

$$\forall n \in [0, N-1] \ \exists i : n \in L_{s_i}$$

and that the total numbers of elements in all $L_{s_i}$ is minimum. 

# Analyzing the Problem
The Problem is the same as Lab1 so it does not need introductions. My approach to a solution was highly based on the olgorithm proposed by the professor during the lectures and then trying to tweak it aiming at better performance overall.

# My proposed solution

## Reference and material
This solution was developed by myself but the beginning stages of the problem solving were brainstormed togheter with my peers after classes. The core of the algorithm is based on:
1. the solution proposed by the professor to solve the [onemax problem](https://github.com/squillero/computational-intelligence/blob/master/2022-23/one-max.ipynb) 
2. slides presented during lectures
3. my notes that can be found [here](https://github.com/lorenzobellino/Computational-Intelligence-2022/blob/main/tests-examples-challenges/evolutionaryComputation/evolution.md)
## early stages of the solution
All my attemps to solve the problem can be found [here](https://github.com/lorenzobellino/Computational-Intelligence-2022/tree/main/tests-examples-challenges/lab2) unfortunately since I was sick during the days before the deadline I had to rush the solution and I did not had enough time to explore more possibilities. For this reason my solution is pretty basic but I think I have found some good strategies. I will try other solution in the future and I will update this file with the results.

## Genetic Algorithm
The core of my solution is standard GA with recombination.
For each Problem space I create a population of $300$ individuals.
Then I calculate an offspring of $200$ individuals that is combined with the parent population. This is done for $100$ generations.
To this standard approach I added a check in order to avoid a steady state, if for 7 generation the bfitness of the best individual does not change I combine the current population with a new one generated from scartch.
my approach is defined here:
```python
population = generate_population(N, all_lists, maxlen)
bestfit = population[0].fitness
for _ in range(NUM_GENERATIONS):
        offspring = generate_offspring(population, all_lists, N, maxlen)
        population = combine(population, offspring)
        steady += 1
        if population[0].fitness > bestfit:
            bestfit = population[0].fitness
            steady = 0
        if steady == 7:
            population = combine(population, generate_population(N, all_lists, maxlen))
            steady = 0
```
## Offspring generation
Each offspring is generated by either **mutation** or **crossover** the parent(s) are chosen with a tournament function with $k=2$.
```python
def tournament(population, tournament_size=2):
    return max(random.choices(population, k=tournament_size), key=lambda i: i.fitness)
```

1. **mutation**:
    the offspring is generated starting from the parent and adding or substituting a list from the original problem.
    With a probability of $0.3$ the new list is added to the genome of the parent.
    ```python
    if random.random() < 0.3:
        o = g[:point] + (random.choice(all_lists),) + g[point:]
    ```
    With a probability of $0.7$ the new list is substituted to the genome of the parent.
    ```python
    else:
        o = g[:point] + (random.choice(all_lists),) + g[point+1:]
    ```
    In the end with a probability of $0.3$ the offspring's genome is shortened by a random amount $l \in [1 , len(g)]$
    ```python
    if random.random() < 0.3:
        o = o[: -random.randint(1, len(o))]
    ```
2. **crossover**:
    The crossover is performed by combining the genome of the two selected parents.
    With a probability of $0.5$ the offspring is generated by combining the first half of the first parent with the second half of the second parent.
    ```python
    if random.random() < 0.5:
        o = g1[:cut] + g2[cut:]
    ```
    With a probability of $0.5$ the offspring is generated by combining the first half of the second parent with the second half of the first parent.
    ```python
    else:
        o = g2[:cut] + g1[cut:]
    ```
    In the end similarly to the mutation phase with a probability of $0.3$ the offspring's genome is shortened by a random amount $l \in [1 , len(g)]$
    ```python
    if random.random() < 0.3:
        o = o[: -random.randint(1, len(o))]
    ```
## Fitness function
The fitness is expressed as a tuple of three values:
1. ```fitness```: the actual fitness calculated by calculating the number of elements already covered by the genome and sumbtracting a penalty that accounts for the repetitions in the genome, the penalty is calculated as ```(duplicates * N / maxlen)``` where ```duplicates``` is the number of duplicates in the genome and ```maxlen``` is the maximum length of the lists in the problem space and ```N``` is the number of elements to cover.
2. ```covered```: the number of elements covered by the genome
3. ```- duplicates```: the number of duplicates in the genome as a negative value since the less repetitions the better.

```python
covered = len(set(loci for gene in genome for loci in gene))
    duplicates = len([loci for gene in genome for loci in gene]) - covered
    fitness = covered - (duplicates * N / maxlen)
    return (fitness, covered, -duplicates)
```
    
## Results
#### $N = 5$
```Solution's weight``` : $5$
```solution's bloat``` : $0$
#### $N = 10$
```Solution's weight``` : $1o$
```solution's bloat``` : $0$
#### $N = 20$
```Solution's weight``` : $27$
```solution's bloat``` : $35$
#### $N = 50$
```Solution's weight``` : $79$
```solution's bloat``` : $58$
#### $N = 100$
```Solution's weight``` : $201$
```solution's bloat``` : $101$
#### $N = 200$
```Solution's weight``` : $487$
```solution's bloat``` : $144$
#### $N = 500$
```Solution's weight``` : $1479$
```solution's bloat``` : $196$
#### $N = 1000$
```Solution's weight``` : $3680$
```solution's bloat``` : $268$
